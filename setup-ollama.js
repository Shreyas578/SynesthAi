// Script to help set up Ollama locally
console.log("ðŸš€ SynesthAI Ollama Setup Guide")
console.log("================================")
console.log("")
console.log("1. Install Ollama:")
console.log("   Visit: https://ollama.ai/download")
console.log("   Or run: curl -fsSL https://ollama.ai/install.sh | sh")
console.log("")
console.log("2. Pull the Mixtral model:")
console.log("   ollama pull mixtral")
console.log("")
console.log("3. Start Ollama server:")
console.log("   ollama serve")
console.log("")
console.log("4. Test the connection:")
console.log("   curl http://localhost:11434/api/tags")
console.log("")
console.log("5. Set environment variables in .env.local:")
console.log("   OLLAMA_BASE_URL=http://localhost:11434")
console.log("   OLLAMA_MODEL=mixtral")
console.log("   QLOO_API_KEY=your_qloo_api_key_here")
console.log("   TMDB_API_KEY=your_tmdb_api_key_here")
console.log("   SPOTIFY_CLIENT_ID=your_spotify_client_id")
console.log("   SPOTIFY_CLIENT_SECRET=your_spotify_client_secret")
console.log("")
console.log("6. Alternative models you can try:")
console.log("   - ollama pull llama2")
console.log("   - ollama pull codellama")
console.log("   - ollama pull openchat")
console.log("")
console.log("âœ¨ Once setup is complete, restart your Next.js development server!")
